{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7590b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6816f01",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "In the context of PyTorch and other deep learning frameworks, tensors are multi-dimensional arrays that represent data. They are fundamental building blocks used for storing and manipulating data in neural networks. Tensors can have different dimensions, such as 0-dimensional (scalar), 1-dimensional (vector), 2-dimensional (matrix), or higher-dimensional arrays.\n",
    "\n",
    "### Here are some key characteristics of tensors:\n",
    "\n",
    "Data Representation: Tensors can represent various types of data, including numerical values (e.g., integers or floating-point numbers), boolean values (True or False), and even categorical data. For example, a grayscale image can be represented as a 2-dimensional tensor, where each element represents the pixel intensity.\n",
    "\n",
    "#### Shape: \n",
    "The shape of a tensor refers to its dimensions or size along each axis. For example, a 2-dimensional tensor representing a grayscale image with dimensions 28x28 would have a shape of (28, 28). Tensors in PyTorch can have arbitrary shapes, allowing for flexibility in representing complex data structures.\n",
    "\n",
    "#### Data Types: \n",
    "Tensors can have different data types, such as integers (int), floating-point numbers (float), or boolean values (bool). PyTorch supports various data types, including 32-bit and 64-bit floating-point numbers (float32 and float64), as well as 8-bit and 16-bit integers (int8 and int16).\n",
    "\n",
    "#### Operations: \n",
    "Tensors support a wide range of mathematical operations, such as addition, subtraction, multiplication, division, matrix multiplication, and more. These operations can be performed element-wise or across specific dimensions of the tensor.\n",
    "\n",
    "#### GPU Acceleration: \n",
    "Tensors can be moved and manipulated on GPU devices to leverage the computational power of GPUs for faster processing. This is particularly useful for training deep neural networks on large datasets, as it allows for parallel computation across multiple GPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9c6009a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floating-Number\n",
    "t1 = tr.tensor(4.)\n",
    "# 4. = 4.0\n",
    "# if wrote just 4 it will be Integer number but in Deep Learning we do lot of computation and \n",
    "# we get float number that's why I wrote 4. instead of 4.0\n",
    "# By default it gives 4 digits after decimal point \" . \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "10637431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "03edfa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.6f}\".format(t1)) # just printing 6 digits after floating point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a89d1cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f5a92e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape # empty list mean just one number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2e36b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tr.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "931c67d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape # only one number in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "cfc0982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer number \n",
    "t2 = tr.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "57813657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9f077b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.0f}\".format(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ccf7834d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3b2227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Try to create more complex Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f37761f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector of Integer\n",
    "t3 = tr.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f219e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b1f9b44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ab94f36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7f3d2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector of float \n",
    "t4 = tr.tensor([1,2.1,3,4,5]) \n",
    "# If we add one float in integers all will be floats by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a449799d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 2.1000, 3.0000, 4.0000, 5.0000])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "007ee34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cd4efe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of Integer\n",
    "t5 = tr.tensor([[1, 2, 3, 4, 5],[6, 7, 8, 9, 10],[11, 12, 13, 14, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "67b52313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1ac35c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a7990485",
   "metadata": {},
   "outputs": [],
   "source": [
    "row , column = t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "39d5135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8a31a549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "8c5c71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of Floats\n",
    "t6 = tr.tensor([[1.1, 2, 3, 4, 5],[6, 7, 8, 9, 10],[11, 12, 13, 14, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8bd0e5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1000,  2.0000,  3.0000,  4.0000,  5.0000],\n",
       "        [ 6.0000,  7.0000,  8.0000,  9.0000, 10.0000],\n",
       "        [11.0000, 12.0000, 13.0000, 14.0000, 15.0000]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "84bd63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D-Array of Integer\n",
    "t5 = tr.tensor([\n",
    "    [[1, 2, 3, 4, 5],[6, 7, 8, 9, 10]],\n",
    "    [[11, 12, 13, 14, 15],[16, 17, 18, 19, 20]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "54669388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10]],\n",
       "\n",
       "        [[11, 12, 13, 14, 15],\n",
       "         [16, 17, 18, 19, 20]]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3ec6100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the \".shape\" property of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9e294ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "bcf9f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, back, column = t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "96696fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "68699e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c2476431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0a540d3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 2 (got 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[355], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3D-Array of Integer \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m t6 \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m      3\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],[ \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m]],\n\u001b[1;32m      4\u001b[0m     [[\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m15\u001b[39m],[\u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m]]\n\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 2 (got 5)"
     ]
    }
   ],
   "source": [
    "# 3D-Array of Integer \n",
    "t6 = tr.tensor([\n",
    "    [[1, 2, 3, 4],[ 7, 8, 9, 10, 11]],\n",
    "    [[11, 12, 14, 15],[17, 18, 19, 20]]\n",
    "])\n",
    "\n",
    "# Error because of different lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313baf1",
   "metadata": {},
   "source": [
    "## Tensor operations and gradients\n",
    "\n",
    "I can combine tensors with the usual arithmetic operations. Let's look an example and see whats happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9418b",
   "metadata": {},
   "source": [
    "I've created 3 tensors `x`, `w` and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a0f04fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6., requires_grad=True), tensor(7., requires_grad=True))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors. for y = wx + b\n",
    "x = torch.tensor(5., requires_grad=False)# False mean we are NOT going to use this Gradient\n",
    "w = torch.tensor(6., requires_grad=True) # True mean we are going to use this Gradient\n",
    "b = torch.tensor(7., requires_grad=True) # True mean we are going to use this Gradient\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da5f86",
   "metadata": {},
   "source": [
    "Let's create a new tensor `y` by combining these tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "aa8a32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmatic operation\n",
    "y = w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6ab564f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09356a2c",
   "metadata": {},
   "source": [
    "As expected, `y` is a tensor with the value `5 * 6 + 7 = 37`. What makes PyTorch special is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. To compute the derivatives, we can call the `.backward` method on our result `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "62f5c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c3622",
   "metadata": {},
   "source": [
    "The derivates of `y` w.r.t the input tensors are stored in the `.grad` property of the respective tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b6a413e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(5.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dx:', x.grad) # because we didn't save as know we make it False\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1c834",
   "metadata": {},
   "source": [
    "As expected, `dy/dw` has the same value as `x` i.e. `5.`, and `dy/db` has the value `1.`. Note that `x.grad` is `None`, because `x` doesn't have `requires_grad` set to `True`. \n",
    "\n",
    "The \"grad\" in `w.grad` stands for gradient, which is another term for derivative, used mainly when dealing with matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ecfc3",
   "metadata": {},
   "source": [
    "## Interoperability with Numpy\n",
    "\n",
    "[Numpy](http://www.numpy.org/) is a popular open source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays, and has a large ecosystem of supporting libraries:\n",
    "\n",
    "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
    "* [OpenCV](https://opencv.org/) for image and video processing\n",
    "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates really well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bd13a",
   "metadata": {},
   "source": [
    "Here's how we create an array in Numpy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "77677f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "76d83597",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ead16e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4d0f7e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20012080",
   "metadata": {},
   "source": [
    "We can convert a Numpy array to s PyTorch using `torch.from_numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e909390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to a tensor.\n",
    "y = tr.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "2644a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c232d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "860df6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ada06a",
   "metadata": {},
   "source": [
    "Now we verify that Numpy Array and Torch Tensor have same Data Types\n",
    "Numpy and PyTorch have one->to->one data type corespondance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "92cea81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data_type, tensor_data_type = x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "aa4c6639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1046fe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1f15478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Tensor to Numpy Array \n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "54707355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "58de812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2acc0",
   "metadata": {},
   "source": [
    "Interoperability between PyTorch and Numpy is essential because most datasets we'll work with will likely be red and preprocessed as Numpy Arrays.\n",
    "Why we need a Library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:<br>\n",
    "\n",
    "<b>Automatic Differentiation:</b> <br>\n",
    "One of the key features of PyTorch is its automatic differentiation capability through the autograd module. This feature allows PyTorch to automatically compute gradients of the loss function with respect to model parameters, facilitating gradient-based optimization methods like gradient descent. While NumPy provides array operations, it doesn't have built-in support for automatic differentiation, which is essential for training neural networks efficiently.\n",
    "\n",
    "<b>GPU Acceleration:</b> <br>\n",
    "PyTorch seamlessly integrates with CUDA, NVIDIA's parallel computing platform, enabling GPU acceleration for numerical computations. This allows PyTorch to leverage the computational power of GPUs for training deep neural networks, resulting in significant speedups compared to CPU-only implementations. While NumPy can be used with GPU-accelerated libraries like CuPy, PyTorch provides a more streamlined approach to GPU programming, especially for deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f4d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
